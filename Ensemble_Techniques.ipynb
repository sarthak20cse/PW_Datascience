{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Theoretical**\n",
        "\n",
        "Q1.Can we use Bagging for regression problems\n",
        "\n",
        "Q2. What is the difference between multiple model training and single model training\n",
        "\n",
        "Q3. Explain the concept of feature randomness in Random Forest\n",
        "\n",
        "Q4. What is OOB (Out-of-Bag) Score\n",
        "\n",
        "Q5. How can you measure the importance of features in a Random Forest model\n",
        "\n",
        "Q6. Explain the working principle of a Bagging Classifier\n",
        "\n",
        "Q7. How do you evaluate a Bagging Classifier’s performance\n",
        "\n",
        "Q8. How does a Bagging Regressor work\n",
        "\n",
        "Q9. What is the main advantage of ensemble techniques\n",
        "\n",
        "Q10. What is the main challenge of ensemble methods\n",
        "\n",
        "Q11. Explain the key idea behind ensemble techniques\n",
        "\n",
        "Q12. What is a Random Forest Classifier\n",
        "\n",
        "Q13. What are the main types of ensemble techniques\n",
        "\n",
        "Q14. What is ensemble learning in machine learning\n",
        "\n",
        "Q15. When should we avoid using ensemble methods\n",
        "\n",
        "Q16. How does Bagging help in reducing overfitting\n",
        "\n",
        "Q17. Why is Random Forest better than a single Decision Tree\n",
        "\n",
        "Q18. What is the role of bootstrap sampling in Bagging\n",
        "\n",
        "Q19. What are some real-world applications of ensemble techniques\n",
        "\n",
        "Q20. What is the difference between Bagging and Boosting?\n",
        "\n",
        "## **Practical**\n",
        "\n",
        "Q21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
        "\n",
        "Q22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
        "\n",
        "Q23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores\n",
        "\n",
        "Q24. Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "\n",
        "Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "\n",
        "Q26. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
        "\n",
        "Q27. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "\n",
        "Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
        "\n",
        "Q29. Train a Random Forest Regressor and analyze feature importance scores\n",
        "\n",
        "Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "\n",
        "Q31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
        "\n",
        "Q32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
        "\n",
        "Q33. Train a Random Forest Classifier and analyze misclassified samples\n",
        "\n",
        "Q34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
        "\n",
        "Q35. Train a Random Forest Classifier and visualize the confusion matrix\n",
        "\n",
        "Q36.Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
        "\n",
        "Q37. Train a Random Forest Classifier and print the top 5 most important features\n",
        "\n",
        "Q38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "\n",
        "Q39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "\n",
        "Q40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare\n",
        "performance\n",
        "\n",
        "Q41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
        "\n",
        "Q42. Train a Bagging Classifier and evaluate its performance using cross-validatio\n",
        "\n",
        "Q43. Train a Random Forest Classifier and plot the Precision-Recall curv\n",
        "\n",
        "Q44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
        "\n",
        "Q45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ],
      "metadata": {
        "id": "nJHKXNk1-8JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.Can we use Bagging for regression problems\n",
        "\n",
        "Yes, Bagging can be used for regression problems. In regression, Bagging trains multiple regression models on different bootstrap samples and averages their predictions to reduce variance and improve stability."
      ],
      "metadata": {
        "id": "G4GTpZaFMkpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the difference between multiple model training and single model training\n",
        "\n",
        "Single model training involves training one model on the full dataset, while multiple model training (ensemble learning) involves training several models and combining their predictions to achieve better performance and robustness."
      ],
      "metadata": {
        "id": "WDCOA4m7OgLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Explain the concept of feature randomness in Random Forest\n",
        "\n",
        "Feature randomness means that at each split in a decision tree, Random Forest considers only a random subset of features instead of all features. This increases diversity among trees and reduces correlation."
      ],
      "metadata": {
        "id": "KnHIDYANOgHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is OOB (Out-of-Bag) Score\n",
        "\n",
        "OOB Score is an internal validation metric in bagging-based models. It evaluates model performance using samples not included in the bootstrap sample for a given tree."
      ],
      "metadata": {
        "id": "ekjTROvuOgFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How can you measure the importance of features in a Random Forest model\n",
        "\n",
        "Feature importance can be measured using mean decrease in impurity (Gini importance) or permutation importance."
      ],
      "metadata": {
        "id": "Dh7IvcIMOgDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Explain the working principle of a Bagging Classifier\n",
        "\n",
        "A Bagging Classifier trains multiple base classifiers on bootstrap samples and combines predictions using majority voting."
      ],
      "metadata": {
        "id": "g1KhhAIDOf9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How do you evaluate a Bagging Classifier’s performance\n",
        "\n",
        "Using metrics such as accuracy, precision, recall, F1-score, ROC-AUC, and cross-validation."
      ],
      "metadata": {
        "id": "D3Bb71s9Of41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. How does a Bagging Regressor work\n",
        "\n",
        "\n",
        "It trains multiple regression models on different bootstrap samples and averages their predictions."
      ],
      "metadata": {
        "id": "qs-OcTuMOf2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the main advantage of ensemble techniques\n",
        "\n",
        "They improve predictive performance and reduce overfitting by combining multiple models."
      ],
      "metadata": {
        "id": "1qpTX9x5Of0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. What is the main challenge of ensemble methods\n",
        "\n",
        "Higher computational cost and reduced interpretability."
      ],
      "metadata": {
        "id": "pjH0LHGwOfyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. Explain the key idea behind ensemble techniques\n",
        "\n",
        "Combining weak or diverse models to create a stronger predictive model."
      ],
      "metadata": {
        "id": "4zxTD8sDOfv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. What is a Random Forest Classifier\n",
        "\n",
        "A Random Forest Classifier is an ensemble of decision trees trained using bagging and feature randomness."
      ],
      "metadata": {
        "id": "E95zo7tkOftt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. What are the main types of ensemble techniques\n",
        "\n",
        "Bagging, Boosting, and Stacking."
      ],
      "metadata": {
        "id": "-d9ZUL_hOfrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. What is ensemble learning in machine learning\n",
        "\n",
        "Ensemble learning combines multiple models to improve accuracy and generalization."
      ],
      "metadata": {
        "id": "8HdZnZspOflq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. When should we avoid using ensemble methods\n",
        "\n",
        "When datasets are small, interpretability is crucial, or computational resources are limited."
      ],
      "metadata": {
        "id": "N2D0Gul4POJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. How does Bagging help in reducing overfitting\n",
        "\n",
        "By reducing variance through training on multiple bootstrap samples"
      ],
      "metadata": {
        "id": "0JFFcBRjPOGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. Why is Random Forest better than a single Decision Tree\n",
        "\n",
        "It reduces overfitting and improves accuracy through ensemble averaging."
      ],
      "metadata": {
        "id": "9fdLG4hAPOET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. What is the role of bootstrap sampling in Bagging\n",
        "\n",
        "It creates diverse training datasets by sampling with replacement."
      ],
      "metadata": {
        "id": "JJPrY-7oPOCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. What are some real-world applications of ensemble techniques\n",
        "\n",
        "Fraud detection, medical diagnosis, recommendation systems, and stock prediction."
      ],
      "metadata": {
        "id": "by0iFp1QPOAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. What is the difference between Bagging and Boosting?\n",
        "\n",
        "Bagging reduces variance using independent models, while Boosting reduces bias by training models sequentially."
      ],
      "metadata": {
        "id": "E_skBB0aPN9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy"
      ],
      "metadata": {
        "id": "Wr9X8FF5PN7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz1H31Me-zVU",
        "outputId": "54c6ba7a-098b-4dee-9215-87eab2428385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging Classifier\n",
        "model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "FLzT15-yPmLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging Regressor\n",
        "model = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# MSE\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWJxDYwHPlwB",
        "outputId": "0b883783-8c32-471c-90d7-c4eae77d9264"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.2572988359842641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores"
      ],
      "metadata": {
        "id": "gE241VnUQAeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Feature Importance\n",
        "print(\"Feature Importances:\")\n",
        "print(rf.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDdIZLE8PrMw",
        "outputId": "ec82caba-68bb-4c1c-be4c-a07173302283"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "[0.03484323 0.01522515 0.06799034 0.06046164 0.00795845 0.01159704\n",
            " 0.06691736 0.10704566 0.00342279 0.00261508 0.0142637  0.00374427\n",
            " 0.01008506 0.02955283 0.00472157 0.00561183 0.00581969 0.00375975\n",
            " 0.00354597 0.00594233 0.08284828 0.01748526 0.0808497  0.13935694\n",
            " 0.01223202 0.01986386 0.03733871 0.13222509 0.00817908 0.00449731]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. Train a Random Forest Regressor and compare its performance with a single Decision Tree"
      ],
      "metadata": {
        "id": "XgIx8kKPQEDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Decision Tree Regressor\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_pred = rf.predict(X_test)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "# MSE Comparison\n",
        "print(\"Random Forest MSE:\", mean_squared_error(y_test, rf_pred))\n",
        "print(\"Decision Tree MSE:\", mean_squared_error(y_test, dt_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eyzratzQCJz",
        "outputId": "cf52981f-6519-435e-f60f-ead7f34e3e67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MSE: 0.2553684927247781\n",
            "Decision Tree MSE: 0.495235205629094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier"
      ],
      "metadata": {
        "id": "QMgalmWWQIKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Random Forest with OOB\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    oob_score=True,\n",
        "    bootstrap=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X, y)\n",
        "\n",
        "# OOB Score\n",
        "print(\"OOB Score:\", rf.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9eY8_A0QGKl",
        "outputId": "a689b5cf-f2e8-407f-e393-d8d5b7458696"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9533333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26. Train a Bagging Classifier using SVM as a base estimator and print accuracy"
      ],
      "metadata": {
        "id": "Yng0Ggy6QQpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging Classifier with SVM\n",
        "model = BaggingClassifier(\n",
        "    estimator=SVC(kernel='rbf', probability=True),\n",
        "    n_estimators=20,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIQcfhL1QJf5",
        "outputId": "40d865a6-336f-44e2-da4a-56011a140aba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27. Train a Random Forest Classifier with different numbers of trees and compare accuracy"
      ],
      "metadata": {
        "id": "vKYLsLxNQT1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_estimators_list = [10, 50, 100, 200]\n",
        "\n",
        "for n in n_estimators_list:\n",
        "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"n_estimators = {n}, Accuracy = {acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csaBBzT9QSPS",
        "outputId": "6483f1d2-7eb1-4c9f-f2db-21188d236010"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators = 10, Accuracy = 1.0\n",
            "n_estimators = 50, Accuracy = 1.0\n",
            "n_estimators = 100, Accuracy = 1.0\n",
            "n_estimators = 200, Accuracy = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score"
      ],
      "metadata": {
        "id": "ES-chem2QW9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Bagging Classifier with Logistic Regression\n",
        "model = BaggingClassifier(\n",
        "    estimator=LogisticRegression(max_iter=1000),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Probability prediction\n",
        "y_prob = model.predict_proba(X_test)\n",
        "\n",
        "# ROC-AUC (macro for multiclass)\n",
        "auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "print(\"ROC-AUC Score:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_tgXX8DQVVq",
        "outputId": "674c2d18-dc04-4de7-826a-c09fce5685cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29. Train a Random Forest Regressor and analyze feature importance scores"
      ],
      "metadata": {
        "id": "VFSJ-lITQaf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Feature Importances\n",
        "print(\"Feature Importances:\")\n",
        "print(rf.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv9DJt0iQYgO",
        "outputId": "cfde17b8-5843-490e-e0d7-24ac8be29dbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "[0.52487148 0.05459322 0.04427185 0.02960631 0.03064978 0.13844281\n",
            " 0.08893574 0.08862881]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy"
      ],
      "metadata": {
        "id": "O6W46Yg1QeVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load classification dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging Classifier\n",
        "bag = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag.fit(X_train, y_train)\n",
        "bag_pred = bag.predict(X_test)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "# Accuracy comparison\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, bag_pred))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_hV8f-XQb9o",
        "outputId": "18410ede-9f58-4772-e3f7-c1fde56ac8a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV"
      ],
      "metadata": {
        "id": "3weYDpR-RFAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# GridSearch\n",
        "grid = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTa1yMnBQfme",
        "outputId": "23cc74cc-b0aa-4077-8671-5190a9da33b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
            "Best Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q32. Train a Bagging Regressor with different numbers of base estimators and compare performance"
      ],
      "metadata": {
        "id": "8rLIGjidRIiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load regression dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "estimators = [10, 50, 100]\n",
        "\n",
        "for n in estimators:\n",
        "    bag = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(),\n",
        "        n_estimators=n,\n",
        "        random_state=42\n",
        "    )\n",
        "    bag.fit(X_train, y_train)\n",
        "    y_pred = bag.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"n_estimators = {n}, MSE = {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-J2vfpNRGS3",
        "outputId": "156f17bd-f2ff-4b3d-c528-3105ba142ed5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators = 10, MSE = 0.2824242776841025\n",
            "n_estimators = 50, MSE = 0.2572988359842641\n",
            "n_estimators = 100, MSE = 0.25592438609899626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q33. Train a Random Forest Classifier and analyze misclassified samples"
      ],
      "metadata": {
        "id": "nE-e_lSkRMF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Misclassified samples\n",
        "misclassified = np.where(y_test != y_pred)\n",
        "\n",
        "print(\"Number of misclassified samples:\", len(misclassified[0]))\n",
        "print(\"Indices of misclassified samples:\", misclassified[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYXH1X9pRKLr",
        "outputId": "2fb5d7bc-dcc2-42bb-9c96-ef0e5bbf6394"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified samples: 0\n",
            "Indices of misclassified samples: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier"
      ],
      "metadata": {
        "id": "_djolLr_RPEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "# Bagging Classifier\n",
        "bag = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag.fit(X_train, y_train)\n",
        "bag_pred = bag.predict(X_test)\n",
        "\n",
        "# Accuracy comparison\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, bag_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFvO9OhWRNe6",
        "outputId": "f99434f1-32c1-4557-e440-c8a69a4edecc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 1.0\n",
            "Bagging Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q35. Train a Random Forest Classifier and visualize the confusion matrix"
      ],
      "metadata": {
        "id": "0pWtG4myRSe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "-vEp6Ya4RQii",
        "outputId": "6c5d1deb-c605-4a37-b280-99c41941bc34"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q36.Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy"
      ],
      "metadata": {
        "id": "iVxa-uzDRasW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Base estimators\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svm', SVC(probability=True)),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "]\n",
        "\n",
        "# Stacking Classifier\n",
        "stack = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "y_pred = stack.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IskN4EdlRTvI",
        "outputId": "b6a9ea74-fd50-411b-b52d-d018b87fda0f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q37. Train a Random Forest Classifier and print the top 5 most important features"
      ],
      "metadata": {
        "id": "EN5zXVa6Rd0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Feature importance\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1][:5]\n",
        "\n",
        "print(\"Top 5 Important Features:\")\n",
        "for i in indices:\n",
        "    print(f\"Feature {i} - Importance: {importances[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBvIen8tRb-g",
        "outputId": "67094926-fb5b-4dab-eae7-88b10a98defc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Important Features:\n",
            "Feature 23 - Importance: 0.13935694286788813\n",
            "Feature 27 - Importance: 0.13222508566399135\n",
            "Feature 7 - Importance: 0.10704565721708294\n",
            "Feature 20 - Importance: 0.08284828183729644\n",
            "Feature 22 - Importance: 0.08084969717184524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score"
      ],
      "metadata": {
        "id": "DPlVwzllRgnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Bagging Classifier\n",
        "bag = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = bag.predict(X_test)\n",
        "\n",
        "# Metrics (macro for multiclass)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeK53He_Re8_",
        "outputId": "fa69e8fe-e5a4-456f-af01-017d34da8a0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy"
      ],
      "metadata": {
        "id": "Gx4TkpEqRmbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depths = [None, 2, 5, 10, 20]\n",
        "\n",
        "for depth in depths:\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=depth,\n",
        "        random_state=42\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"max_depth = {depth}, Accuracy = {acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCSFlJqZRke-",
        "outputId": "390ae995-0970-4d27-e290-056c8af22bb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth = None, Accuracy = 1.0\n",
            "max_depth = 2, Accuracy = 1.0\n",
            "max_depth = 5, Accuracy = 1.0\n",
            "max_depth = 10, Accuracy = 1.0\n",
            "max_depth = 20, Accuracy = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance"
      ],
      "metadata": {
        "id": "BYtJTYNVRpeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Load regression dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Decision Tree base estimator\n",
        "bag_dt = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_dt.fit(X_train, y_train)\n",
        "dt_pred = bag_dt.predict(X_test)\n",
        "\n",
        "# KNN base estimator\n",
        "bag_knn = BaggingRegressor(\n",
        "    estimator=KNeighborsRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bag_knn.fit(X_train, y_train)\n",
        "knn_pred = bag_knn.predict(X_test)\n",
        "\n",
        "# Performance comparison\n",
        "print(\"Bagging DT MSE:\", mean_squared_error(y_test, dt_pred))\n",
        "print(\"Bagging KNN MSE:\", mean_squared_error(y_test, knn_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VH6iPCSRnnY",
        "outputId": "65ed7bf1-9d6f-4bfd-8594-cae49d52ab0d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging DT MSE: 0.2572988359842641\n",
            "Bagging KNN MSE: 1.0762752887085227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score"
      ],
      "metadata": {
        "id": "KA6fx6I6Rv-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load binary classification dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ROC-AUC Score\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8-TrmdmRqrQ",
        "outputId": "df0f2d73-b8c4-429e-c3b7-312252d65f89"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9952505732066819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q42. Train a Bagging Classifier and evaluate its performance using cross-validatio"
      ],
      "metadata": {
        "id": "YPM0zg1fRzmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Bagging Classifier\n",
        "bag = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Cross-validation\n",
        "scores = cross_val_score(bag, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeRrOLAnRxZo",
        "outputId": "8a863994-b2ac-4a33-a982-17fe8cdfb321"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean Accuracy: 0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q43. Train a Random Forest Classifier and plot the Precision-Recall curv"
      ],
      "metadata": {
        "id": "JLhkUAqzR3C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "9Ki1JjmwR1FY",
        "outputId": "75891cd1-6ba3-41d4-ea03-d9bfed52919e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy"
      ],
      "metadata": {
        "id": "f7qniDlMR5-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "]\n",
        "\n",
        "# Stacking Classifier\n",
        "stack = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "y_pred = stack.predict(X_test)\n",
        "\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgVKE7_DR4Sw",
        "outputId": "785f0585-d3fe-49aa-aef2-5bb68cd067f8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance"
      ],
      "metadata": {
        "id": "sCcU8rYFR9e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load regression dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# With bootstrap\n",
        "bag_bootstrap = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    bootstrap=True,\n",
        "    random_state=42\n",
        ")\n",
        "bag_bootstrap.fit(X_train, y_train)\n",
        "pred_bootstrap = bag_bootstrap.predict(X_test)\n",
        "\n",
        "# Without bootstrap\n",
        "bag_no_bootstrap = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    bootstrap=False,\n",
        "    random_state=42\n",
        ")\n",
        "bag_no_bootstrap.fit(X_train, y_train)\n",
        "pred_no_bootstrap = bag_no_bootstrap.predict(X_test)\n",
        "\n",
        "# Performance comparison\n",
        "print(\"MSE with Bootstrap:\", mean_squared_error(y_test, pred_bootstrap))\n",
        "print(\"MSE without Bootstrap:\", mean_squared_error(y_test, pred_no_bootstrap))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISisptW5R7sY",
        "outputId": "254aad4e-f865-4304-ec2a-bd87fdd3b969"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with Bootstrap: 0.2572988359842641\n",
            "MSE without Bootstrap: 0.4654684668067983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqT9_sbxR-9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}