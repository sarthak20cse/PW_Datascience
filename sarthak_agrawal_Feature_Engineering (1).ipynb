{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment Questions**\n",
        "\n",
        "1. What is a parameter?\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "\n",
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "6. What are continuous and categorical variables?\n",
        "\n",
        "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "8. What do you mean by training and testing a dataset?\n",
        "\n",
        "9. What is sklearn.preprocessing?\n",
        "\n",
        "10. What is a test set?\n",
        "\n",
        "11. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "12. How do you approach a Machine Learning problem?\n",
        "\n",
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "\n",
        "15. What is causation? Explain the difference between correlation and causation with an example.\n",
        "\n",
        "16. What is an optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "17. What is sklearn.linear_model?\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "20. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "21. How do we perform scaling in Python?\n",
        "\n",
        "22. Explain data encoding."
      ],
      "metadata": {
        "id": "_YyDbnqDI3ov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1. What is a parameter?**\n",
        "A parameter is a numerical value inside a model that the algorithm learns during training.  \n",
        "Example: In linear regression `y = mx + c`, **m** and **c** are parameters.\n"
      ],
      "metadata": {
        "id": "t6ESImjVsGMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q2. What is correlation?**\n",
        "Correlation shows how strongly two variables are related to each other."
      ],
      "metadata": {
        "id": "kczg8aACsW-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q3. What does negative correlation mean?**\n",
        "Negative correlation means:\n",
        "- One variable ‚Üë increases  \n",
        "- Other variable ‚Üì decreases"
      ],
      "metadata": {
        "id": "iVI85YY5sdS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q4. Define Machine Learning. What are the main components in Machine Learning?**\n",
        "Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables computers to learn patterns from data and make predictions or decisions **without being explicitly programmed**.\n",
        "\n",
        "In simple terms:\n",
        "\n",
        "**Machine Learning = Learning patterns from data + Making predictions**\n",
        "\n",
        "---\n",
        "\n",
        "## **Main Components in Machine Learning**\n",
        "\n",
        "### **1. Data**\n",
        "The raw information used by the model to learn.  \n",
        "Examples: images, numbers, text, sensor data.\n",
        "\n",
        "### **2. Model**\n",
        "A mathematical function that learns patterns from data.  \n",
        "Examples: Linear Regression, Decision Trees, Neural Networks.\n",
        "\n",
        "### **3. Features**\n",
        "The input variables used to make predictions.  \n",
        "Example: For house price prediction ‚Üí size, rooms, location.\n",
        "\n",
        "### **4. Labels / Target**\n",
        "The actual output values the model tries to learn.  \n",
        "Example: House price = ‚Çπ50,00,000.\n",
        "\n",
        "### **5. Training**\n",
        "The process where the model learns from the data by adjusting parameters.\n",
        "\n",
        "### **6. Loss Function**\n",
        "A metric that shows how wrong the model's predictions are.  \n",
        "Examples: MSE, Cross-Entropy.\n",
        "\n",
        "### **7. Optimization Algorithm**\n",
        "Used to reduce the loss function and improve learning.  \n",
        "Example: Gradient Descent.\n",
        "\n",
        "### **8. Evaluation**\n",
        "Checking model performance on unseen (test) data.  \n",
        "Metrics: Accuracy, Precision, Recall, RMSE.\n",
        "\n",
        "### **9. Prediction / Inference**\n",
        "Using the trained model to predict outcomes on new data."
      ],
      "metadata": {
        "id": "EUEBwBQ8shA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q5. How does loss value help in determining whether the model is good or not?**\n",
        "\n",
        "The **loss value** tells us **how far the model's predictions are from the actual target values**.\n",
        "\n",
        "- A **low loss value** means the model is performing well.\n",
        "- A **high loss value** means the model is performing poorly.\n",
        "\n",
        "During training:\n",
        "- The model tries to **minimize the loss** using algorithms like Gradient Descent.\n",
        "- If the loss is **consistently decreasing**, the model is learning properly.\n",
        "- If the loss is **not decreasing**, the model is not improving or may be overfitting/underfitting.\n",
        "\n",
        "**In simple terms:**  \n",
        "Loss value is the **score of the model‚Äôs mistakes**.  \n",
        "**Lower score = Better model.**\n"
      ],
      "metadata": {
        "id": "BmMiwLWHsjzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q6. What are continuous and categorical variables?**\n",
        "- **Continuous variables:** Numeric values (salary, height, temperature)  \n",
        "- **Categorical variables:** Labels (gender, city, color)\n"
      ],
      "metadata": {
        "id": "gPYmcSzDtVF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q7. How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "\n",
        "Categorical variables contain **text labels** instead of numbers (e.g., \"Male\", \"Female\", \"Red\", \"Blue\").  \n",
        "Machine Learning models **cannot use text directly**, so we convert them into numbers.  \n",
        "This process is known as **Encoding**.\n",
        "\n",
        "### ‚úÖ Common Techniques to Handle Categorical Variables:\n",
        "\n",
        "#### 1. **Label Encoding**\n",
        "- Converts categories into numbers like 0, 1, 2, ...\n",
        "- Example:  \n",
        "  `[\"Red\", \"Blue\", \"Green\"] ‚Üí [0, 1, 2]`\n",
        "- Works well for **ordinal** data.\n",
        "\n",
        "#### 2. **One-Hot Encoding**\n",
        "- Creates new columns with 0/1 values.\n",
        "- Example:  \n",
        "  \"Color\" ‚Üí `Color_Red`, `Color_Blue`, `Color_Green`\n",
        "- Preferred for **nominal** data.\n",
        "\n",
        "#### 3. **Ordinal Encoding**\n",
        "- Used when categories have a **natural order**.\n",
        "- Example:  \n",
        "  `[\"Low\", \"Medium\", \"High\"] ‚Üí [1, 2, 3]`\n",
        "\n",
        "#### 4. **Target Encoding**\n",
        "- Replace each category with the **average target value**.\n",
        "- Used in **tree-based models** and large datasets.\n",
        "\n",
        "#### 5. **Frequency Encoding**\n",
        "- Replace categories with how frequently they appear.\n",
        "- Example:  \n",
        "  `{\"Red\": 50, \"Blue\": 30, \"Green\": 20}`\n",
        "\n",
        "---\n",
        "\n",
        "### **In short:**\n",
        "We convert text categories into numeric values so ML models can understand them.  \n",
        "Common methods: **Label Encoding, One-Hot Encoding, Ordinal Encoding, Target Encoding, Frequency Encoding.**\n"
      ],
      "metadata": {
        "id": "9W9hFmlRtYRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q8. What do you mean by training and testing a dataset?**\n",
        "\n",
        "In Machine Learning, a dataset is usually divided into **two parts**:\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 1. Training Dataset\n",
        "- This is the **data used to teach the model**.\n",
        "- The model learns patterns, relationships, and rules from this data.\n",
        "- Example:  \n",
        "  If you're building a model to predict house prices, the training data includes houses and their prices.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 2. Testing Dataset\n",
        "- This data is **not shown to the model during training**.\n",
        "- It is used to **check how well the model performs** on new, unseen data.\n",
        "- Helps evaluate the model‚Äôs accuracy, performance, and generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Why do we split the dataset?\n",
        "If we train and test the model on the **same data**, the model will look perfect but will fail in the real world.\n",
        "\n",
        "So we split the dataset (commonly 80% training, 20% testing) to ensure the model:\n",
        "\n",
        "- **Learns** from training data  \n",
        "- **Is evaluated** on testing data  \n",
        "\n",
        "---\n",
        "\n",
        "### ‚úîÔ∏è In simple words:\n",
        "- **Training data = learn**  \n",
        "- **Testing data = check performance**\n"
      ],
      "metadata": {
        "id": "SDdyU_VWtapi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q9. What is sklearn.preprocessing?**\n",
        "A module used for:\n",
        "- scaling  \n",
        "- normalization  \n",
        "- encoding  \n",
        "- feature transformations"
      ],
      "metadata": {
        "id": "qOi9OFp2tdK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q10. What is a test set?**\n",
        "The portion of dataset used ONLY to evaluate the model.\n"
      ],
      "metadata": {
        "id": "nQbXsEUAtfzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q11. How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "We usually use the `train_test_split()` function from **scikit-learn** to split a dataset into:\n",
        "- **Training data**\n",
        "- **Testing data**\n",
        "\n",
        "This helps us train the model on one part and evaluate it on another unseen part.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Example Code in Python (Google Colab)\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Age\": [22, 25, 47, 52, 46, 56, 23, 34],\n",
        "    \"Salary\": [20000, 25000, 47000, 52000, 46000, 56000, 21000, 34000],\n",
        "    \"Buy\": [0, 0, 1, 1, 1, 1, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting features (X) and target (y)\n",
        "X = df[[\"Age\", \"Salary\"]]\n",
        "y = df[\"Buy\"]\n",
        "\n",
        "# Split the data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Display output\n",
        "X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "86qGJfpUtjaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q12. How do you approach a Machine Learning problem?**\n",
        "\n",
        "Understand problem\n",
        "\n",
        "Collect data\n",
        "\n",
        "Clean data\n",
        "\n",
        "EDA\n",
        "\n",
        "Feature engineering\n",
        "\n",
        "Select model\n",
        "\n",
        "Train\n",
        "\n",
        "Evaluate\n",
        "\n",
        "Deploy"
      ],
      "metadata": {
        "id": "r5O1z9satwpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q13. Why do we have to perform EDA before fitting a model to the data?**\n",
        "\n",
        "**EDA (Exploratory Data Analysis)** is the process of exploring and understanding the data *before* building a Machine Learning model.\n",
        "\n",
        "It helps us identify important patterns, detect errors, and decide how to clean or prepare the data.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Reasons Why EDA Is Important:\n",
        "\n",
        "### **1. Understand the data**\n",
        "- Check shapes, summary statistics, missing values, duplicates.\n",
        "- Helps you know what type of model will fit best.\n",
        "\n",
        "### **2. Detect outliers and noise**\n",
        "- Outliers can negatively affect model performance.\n",
        "- EDA helps visualize and handle them.\n",
        "\n",
        "### **3. Identify missing values**\n",
        "- Missing data must be imputed or removed.\n",
        "- Models cannot work well with missing values.\n",
        "\n",
        "### **4. Check data distributions**\n",
        "- Helps decide transformations (log transform, normalization, scaling).\n",
        "\n",
        "### **5. Understand relationships between variables**\n",
        "- Using correlation, scatter plots, heatmaps.\n",
        "- Helps identify important features for the model.\n",
        "\n",
        "### **6. Prevent incorrect assumptions**\n",
        "- EDA ensures you don‚Äôt blindly trust the raw dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úîÔ∏è In simple words:\n",
        "EDA tells you:\n",
        "- **What your data looks like**\n",
        "- **What problems exist in the data**\n",
        "- **How to clean and prepare it**\n",
        "- **Which model will work best**\n",
        "\n",
        "**Without EDA, your model may perform badly or give wrong results.**\n"
      ],
      "metadata": {
        "id": "nJ_2XFKRuzHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q14. How can you find correlation between variables in Python?**\n",
        "\n",
        "Correlation tells us **how strongly two variables are related**.  \n",
        "In Python, we usually calculate correlation using **Pandas**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 1. Using `df.corr()`  \n",
        "This gives the correlation matrix for all numeric columns.\n",
        "\n",
        "### **Example Code**\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    \"Age\": [22, 25, 30, 35, 40],\n",
        "    \"Salary\": [20000, 25000, 30000, 40000, 50000],\n",
        "    \"Experience\": [1, 2, 3, 5, 7]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Find correlation\n",
        "correlation_matrix = df.corr()\n",
        "correlation_matrix\n"
      ],
      "metadata": {
        "id": "s1nwD5KDvsC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q15.  What is causation? Explain difference between correlation and causation with an example.**\n",
        "\n",
        "---\n",
        "\n",
        "**Causation** means **one variable directly causes a change in another variable**.  \n",
        "In simple words:  \n",
        "**A ‚Üí causes ‚Üí B**\n",
        "\n",
        "Example:  \n",
        "More hours of study **cause** higher marks.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Correlation vs Causation\n",
        "\n",
        "### **Correlation**\n",
        "- Two variables **move together**.\n",
        "- But one does **NOT necessarily cause** the other to change.\n",
        "- It may be due to coincidence or a hidden factor.\n",
        "\n",
        "### **Causation**\n",
        "- One variable **directly affects** the other.\n",
        "- There is a **cause-and-effect relationship**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚≠ê Example to Understand the Difference\n",
        "\n",
        "### **Example 1: Correlation (No causation)**\n",
        "Ice cream sales ‚Üë  \n",
        "Drowning cases ‚Üë  \n",
        "\n",
        "These two are correlated because both increase in summer.  \n",
        "But **buying ice cream does NOT cause drowning**.\n",
        "\n",
        "The hidden factor = **temperature (summer)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example 2: Causation**\n",
        "Amount of fertilizer ‚Üë  \n",
        "Crop yield ‚Üë  \n",
        "\n",
        "Here fertilizer **directly causes** the crops to grow.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úîÔ∏è In simple words:\n",
        "- **Correlation** = two things happen together.  \n",
        "- **Causation** = one thing happens *because* of the other.\n"
      ],
      "metadata": {
        "id": "FzGlio1AwGaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "\n",
        "---\n",
        "\n",
        "An **optimizer** is an algorithm that adjusts the model‚Äôs **weights** to **minimize the loss function** during training.\n",
        "\n",
        "In simple words:  \n",
        "**Optimizer = helps the model learn faster and better.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### 1. **Gradient Descent**\n",
        "- Calculates the gradient (slope) of the loss function.\n",
        "- Updates weights in the opposite direction of the gradient.\n",
        "\n",
        "Formula:  \n",
        "`new_weight = old_weight - learning_rate * gradient`\n",
        "\n",
        "#### Example:\n",
        "```python\n",
        "# Pseudo example\n",
        "weight = weight - lr * gradient\n"
      ],
      "metadata": {
        "id": "1pWgttIBwKRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **17. What is sklearn.linear_model?**\n",
        "\n",
        "A module containing:\n",
        "\n",
        "LinearRegression\n",
        "\n",
        "LogisticRegression\n",
        "\n",
        "Ridge\n",
        "\n",
        "Lasso\n",
        "\n",
        "SGDRegressor"
      ],
      "metadata": {
        "id": "2XFPVqElwOhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q18. What does `model.fit()` do? What arguments must be given?**\n",
        "\n",
        "---\n",
        "\n",
        "`model.fit()` is the function used to **train the machine learning model**.\n",
        "\n",
        "It does the following:\n",
        "\n",
        "1. **Feeds training data to the model**\n",
        "2. **Calculates loss**\n",
        "3. **Updates weights using the optimizer**\n",
        "4. **Repeats the process for many epochs**\n",
        "5. **Learns the best patterns from the data**\n",
        "\n",
        "In simple words:  \n",
        "`model.fit()` = **Train the model using X (inputs) and y (labels)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. X (Features/Input Data)**\n",
        "The data used to make predictions.  \n",
        "Example: Age, Salary, Experience.\n",
        "\n",
        "### **2. y (Target/Labels)**\n",
        "The correct output values.  \n",
        "Example: 0/1 for classification.\n",
        "\n",
        "### **3. epochs**\n",
        "How many times the entire dataset is passed through the model.\n",
        "\n",
        "### **4. batch_size**\n",
        "How many samples are processed before updating weights.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Optional (Common) Arguments\n",
        "\n",
        "| Argument | Meaning |\n",
        "|---------|---------|\n",
        "| `validation_data` | Helps check accuracy on unseen data during training |\n",
        "| `callbacks` | Early stopping, saving model, etc. |\n",
        "| `verbose` | Controls how training output is displayed |\n",
        "| `shuffle` | Whether to shuffle the data |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Example in Keras (Google Colab)\n",
        "\n",
        "```python\n",
        "model.fit(\n",
        "    X_train,           # features\n",
        "    y_train,           # target\n",
        "    epochs=10,         # number of passes\n",
        "    batch_size=32,     # samples per update\n",
        "    validation_split=0.2,  # 20% data for validation\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "5QZvbzZjfIwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q19. What does `model.predict()` do? What arguments must be given?**\n",
        "\n",
        "---\n",
        "\n",
        "`model.predict()` is used **after training** to make predictions on new or unseen data.\n",
        "\n",
        "It takes the input features **X** and returns the model‚Äôs output.\n",
        "\n",
        "In simple words:  \n",
        "`model.predict()` = **Use the trained model to make predictions.**\n",
        "\n",
        "---\n",
        "\n",
        "1. Takes **input data**\n",
        "2. Passes it through the trained model\n",
        "3. Applies learned weights\n",
        "4. Outputs the prediction  \n",
        "   - Regression ‚Üí numeric value  \n",
        "   - Classification ‚Üí probabilities or class labels\n",
        "\n",
        "---\n",
        "\n",
        "### **1. X (Input data / features)**\n",
        "The only required argument.\n",
        "\n",
        "Example:\n",
        "- A list of numbers  \n",
        "- A numpy array  \n",
        "- A DataFrame  \n",
        "- A single sample or multiple samples\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Optional Arguments\n",
        "\n",
        "| Argument | Purpose |\n",
        "|----------|---------|\n",
        "| `batch_size` | Predict in batches for large datasets |\n",
        "| `verbose` | Controls progress output |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Example in Keras (Google Colab)\n",
        "\n",
        "```python\n",
        "# Predict using test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Display results\n",
        "predictions[:5]\n"
      ],
      "metadata": {
        "id": "dVWrr33zfPlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q20. What is Feature Scaling? How does it help in Machine Learning?**\n",
        "\n",
        "---\n",
        "\n",
        "**Feature Scaling** is the process of transforming all numeric features to the **same scale**  \n",
        "so that no variable dominates others just because of larger values.\n",
        "\n",
        "Examples:\n",
        "- Age ‚Üí 21, 25, 40  \n",
        "- Salary ‚Üí 20,000; 50,000; 90,000  \n",
        "\n",
        "Salary is much larger in magnitude, so the model may give it more importance.  \n",
        "Feature scaling fixes this problem.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úîÔ∏è 1. Helps the model learn faster  \n",
        "Algorithms like Gradient Descent converge **much faster** when features are on the same scale.\n",
        "\n",
        "### ‚úîÔ∏è 2. Prevents dominance of large-value features  \n",
        "Large numerical values do not overshadow smaller valued features after scaling.\n",
        "\n",
        "### ‚úîÔ∏è 3. Essential for distance-based algorithms  \n",
        "Models like:\n",
        "- KNN  \n",
        "- K-means  \n",
        "- SVM  \n",
        "\n",
        "use distances between points. Without scaling, results become incorrect.\n",
        "\n",
        "### ‚úîÔ∏è 4. Improves accuracy and stability  \n",
        "Scaled features make training more stable and improve model performance.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Common Feature Scaling Techniques\n",
        "\n",
        "### **1. Min-Max Scaling (Normalization)**  \n",
        "Converts values to a range **0 to 1**.\n",
        "\n",
        "Formula:  \n",
        "`X_scaled = (X - X_min) / (X_max - X_min)`\n",
        "\n",
        "Example:\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform([[10], [20], [30]])\n",
        "scaled\n"
      ],
      "metadata": {
        "id": "_6QW0uygfpFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q21. How do we perform scaling in Python?**\n",
        "\n",
        "We use preprocessing tools from **scikit-learn** such as:\n",
        "- `MinMaxScaler` (Normalization)\n",
        "- `StandardScaler` (Standardization)\n",
        "\n",
        "These scalers transform numeric features into a similar range so the model can learn better.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 1. Min-Max Scaling (Normalization)\n",
        "Scales values between **0 and 1**.\n",
        "\n",
        "### **Example Code**\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Sample data\n",
        "data = {\"Age\": [20, 30, 40, 50], \"Salary\": [20000, 40000, 60000, 80000]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "scaled_data\n"
      ],
      "metadata": {
        "id": "dzPTWchd-5Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hkcL__7i_HLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q22. Explain data encoding.**\n",
        "\n",
        "Data encoding is the process of converting categorical (non-numeric) data into a numeric format so that Machine Learning models can understand and use it. Most ML algorithms work only with numbers, so encoding is necessary when your dataset contains labels like colors, names, categories, or yes/no values. There are several common encoding techniques. Label Encoding converts each category into a unique integer (for example, Red = 0, Blue = 1, Green = 2). It is simple but may accidentally introduce an order where none exists. One-Hot Encoding avoids this by creating separate binary columns for each category (e.g., Color_Red, Color_Blue, Color_Green), making it suitable for nominal data with no order. Ordinal Encoding is used when the categories have a natural order such as Low < Medium < High. Encoding helps algorithms interpret categorical features correctly and improves the performance of machine learning models."
      ],
      "metadata": {
        "id": "t2pgBZ5HfsTA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBbyNJk2fMUV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IG0h3XUqfw8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}