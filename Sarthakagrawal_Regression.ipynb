{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression**\n",
        "## **Assignment Questions**\n",
        "\n",
        "\n",
        "Q1. What is Simple Linear Regression\n",
        "\n",
        "Q2. What are the key assumptions of Simple Linear Regression\n",
        "\n",
        "Q3. What does the coefficient m represent in the equation Y=mX+c\n",
        "\n",
        "Q4. What does the intercept c represent in the equation Y=mX+c\n",
        "\n",
        "Q5. How do we calculate the slope m in Simple Linear Regression\n",
        "\n",
        "Q6. What is the purpose of the least squares method in Simple Linear Regression\n",
        "\n",
        "Q7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
        "\n",
        "Q8. What is Multiple Linear Regression\n",
        "\n",
        "Q9. What is the main difference between Simple and Multiple Linear Regression\n",
        "\n",
        "Q10. What are the key assumptions of Multiple Linear Regression\n",
        "\n",
        "Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n",
        "\n",
        "Q12. How can you improve a Multiple Linear Regression model with high multicollinearity\n",
        "\n",
        "Q13. What are some common techniques for transforming categorical variables for use in regression models\n",
        "\n",
        "Q14. What is the role of interaction terms in Multiple Linear Regression\n",
        "\n",
        "Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
        "\n",
        "Q16. What is the significance of the slope in regression analysis, and how does it affect predictions\n",
        "\n",
        "Q17. What are the limitations of using R² as a sole measure of model performance\n",
        "\n",
        "Q18. How would you interpret a large standard error for a regression coefficient\n",
        "\n",
        "Q19. What is polynomial regression\n",
        "\n",
        "Q20. When is polynomial regression used\n",
        "\n",
        "Q21. How does the intercept in a regression model provide context for the relationship between variables\n",
        "\n",
        "Q22. How can heteroscedasticity be identified in residual plots, and why is it important to address it\n",
        "\n",
        "Q23. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²\n",
        "\n",
        "Q24. Why is it important to scale variables in Multiple Linear Regression\n",
        "\n",
        "Q25. How does polynomial regression differ from linear regression\n",
        "\n",
        "Q26. What is the general equation for polynomial regression\n",
        "\n",
        "Q27. Can polynomial regression be applied to multiple variables\n",
        "\n",
        "Q28. What are the limitations of polynomial regression\n",
        "\n",
        "Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial\n",
        "\n",
        "Q30. Why is visualization important in polynomial regression\n",
        "\n",
        "Q31. How is polynomial regression implemented in PythonNB   "
      ],
      "metadata": {
        "id": "lJ8gBjjkXub9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Simple Linear Regression\n",
        "\n",
        "Simple Linear Regression is a statistical technique used to model the relationship between one independent variable (X) and one dependent variable (Y). It assumes a linear relationship between X and Y and represents it using the equation Y = mX + c, where m is the slope and c is the intercept."
      ],
      "metadata": {
        "id": "suNlckQAdvF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the key assumptions of Simple Linear Regression\n",
        "\n",
        "The key assumptions are linearity between X and Y, independence of observations, homoscedasticity (constant variance of errors), normality of residuals, and no significant outliers influencing the model."
      ],
      "metadata": {
        "id": "vxHb_Rtfd0-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What does the coefficient m represent in the equation Y = mX + c\n",
        "\n",
        "The coefficient m represents the slope of the line. It indicates how much the dependent variable Y changes for a one-unit increase in the independent variable X."
      ],
      "metadata": {
        "id": "NNptDM8vd17u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What does the intercept c represent in the equation Y = mX + c\n",
        "\n",
        "The intercept c represents the value of Y when X is equal to zero. It shows where the regression line crosses the Y-axis."
      ],
      "metadata": {
        "id": "g7V8-JWnd4Yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How do we calculate the slope m in Simple Linear Regression\n",
        "\n",
        "The slope m is calculated as the ratio of the covariance of X and Y to the variance of X. It measures the direction and strength of the linear relationship between X and Y."
      ],
      "metadata": {
        "id": "BLdGPJKGd_V-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What is the purpose of the least squares method in Simple Linear Regression\n",
        "\n",
        "The least squares method minimizes the sum of the squared differences between the actual values and the predicted values, ensuring the best-fitting regression line."
      ],
      "metadata": {
        "id": "uBegSFYYeD1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
        "\n",
        "R² represents the proportion of variance in the dependent variable that is explained by the independent variable. Its value ranges from 0 to 1."
      ],
      "metadata": {
        "id": "eT2aCwuweGjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What is Multiple Linear Regression\n",
        "\n",
        "Multiple Linear Regression is an extension of linear regression that models the relationship between one dependent variable and two or more independent variables."
      ],
      "metadata": {
        "id": "KNMaWp-weJfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the main difference between Simple and Multiple Linear Regression\n",
        "\n",
        "Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses multiple independent variables to predict the dependent variable."
      ],
      "metadata": {
        "id": "rf2UANBWeLxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. What are the key assumptions of Multiple Linear Regression\n",
        "\n",
        "The assumptions include linearity, independence of errors, homoscedasticity, normality of residuals, no multicollinearity, and no significant outliers."
      ],
      "metadata": {
        "id": "tPDnMxmWeOYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\n",
        "\n",
        "Heteroscedasticity occurs when the variance of residuals is not constant. It can lead to unreliable standard errors and incorrect statistical inferences."
      ],
      "metadata": {
        "id": "1H1a0L9OeSQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. How can you improve a Multiple Linear Regression model with high multicollinearity\n",
        "\n",
        "Multicollinearity can be reduced by removing highly correlated variables, using dimensionality reduction techniques, or applying regularization methods like Ridge Regression."
      ],
      "metadata": {
        "id": "vKYD1haceVoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. What are some common techniques for transforming categorical variables for use in regression models\n",
        "\n",
        "Common techniques include one-hot encoding, label encoding, and dummy variable creation."
      ],
      "metadata": {
        "id": "l4HCmIEKeX_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. What is the role of interaction terms in Multiple Linear Regression\n",
        "\n",
        "Interaction terms capture the combined effect of two or more independent variables on the dependent variable when their effect is not purely additive."
      ],
      "metadata": {
        "id": "7hLpZTpGeeMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
        "\n",
        "In Simple Linear Regression, the intercept is easier to interpret, while in Multiple Linear Regression it represents the value of Y when all independent variables are zero, which may not always be meaningful."
      ],
      "metadata": {
        "id": "ecrwDxFeegRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. What is the significance of the slope in regression analysis, and how does it affect predictions\n",
        "\n",
        "The slope determines the direction and magnitude of change in the dependent variable, directly influencing the model’s predictions."
      ],
      "metadata": {
        "id": "AXJsSW88eifn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. What are the limitations of using R² as a sole measure of model performance\n",
        "\n",
        "R² does not indicate causation, can increase with irrelevant variables, and does not account for overfitting. Adjusted R² is often preferred."
      ],
      "metadata": {
        "id": "QFI2AfCoek6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. How would you interpret a large standard error for a regression coefficient\n",
        "\n",
        "A large standard error indicates uncertainty in the coefficient estimate, suggesting the variable may not be statistically significant."
      ],
      "metadata": {
        "id": "cc7knGMTenFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. What is polynomial regression\n",
        "\n",
        "Polynomial regression models the relationship between variables as an nth-degree polynomial, allowing it to capture non-linear patterns."
      ],
      "metadata": {
        "id": "lKNkb0InepSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. When is polynomial regression used\n",
        "\n",
        "Polynomial regression is used when the relationship between variables is non-linear but can be approximated by a polynomial curve."
      ],
      "metadata": {
        "id": "QOfznY_OerS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. How does the intercept in a regression model provide context for the relationship between variables\n",
        "\n",
        "The intercept provides a baseline value of the dependent variable and helps contextualize predictions when independent variables are near zero."
      ],
      "metadata": {
        "id": "-AVu8BZ0etWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. How can heteroscedasticity be identified in residual plots, and why is it important to address it\n",
        "\n",
        "It is identified when residuals show a funnel or pattern instead of random spread. Addressing it improves model reliability and inference accuracy."
      ],
      "metadata": {
        "id": "taFhBcCoevqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²\n",
        "\n",
        "It suggests that unnecessary variables are inflating R² and the model may be overfitting."
      ],
      "metadata": {
        "id": "XqlRS-uoex1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. Why is it important to scale variables in Multiple Linear Regression\n",
        "\n",
        "Scaling ensures all variables contribute equally, improves numerical stability, and helps models that are sensitive to feature magnitude."
      ],
      "metadata": {
        "id": "nXp0nVhZezyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. How does polynomial regression differ from linear regression\n",
        "\n",
        "Linear regression fits a straight line, while polynomial regression fits a curved line by adding higher-degree terms."
      ],
      "metadata": {
        "id": "CUyw47Fee2BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26. What is the general equation for polynomial regression\n",
        "\n",
        "The general equation is\n",
        "Y = a₀ + a₁X + a₂X² + a₃X³ + … + aₙXⁿ"
      ],
      "metadata": {
        "id": "Xq7TyevqfLmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27. Can polynomial regression be applied to multiple variables\n",
        "\n",
        "Yes, polynomial regression can be extended to multiple variables by adding polynomial terms for each feature."
      ],
      "metadata": {
        "id": "tU5veR-UfN6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28. What are the limitations of polynomial regression\n",
        "\n",
        "It can overfit data, perform poorly outside the data range, and become computationally complex for high degrees."
      ],
      "metadata": {
        "id": "mmHuz7iKfRzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial\n",
        "\n",
        "Cross-validation, adjusted R², AIC, BIC, and validation error are commonly used."
      ],
      "metadata": {
        "id": "JB9JGLrVfUe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30. Why is visualization important in polynomial regression\n",
        "\n",
        "Visualization helps identify non-linear trends, detect overfitting, and understand how well the model fits the data."
      ],
      "metadata": {
        "id": "golRB96wfWoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31. How is polynomial regression implemented in PythonNB\n",
        "\n",
        "Polynomial regression in Python is implemented using PolynomialFeatures from sklearn.preprocessing along with LinearRegression to fit the transformed features."
      ],
      "metadata": {
        "id": "0GlVcx7bfY65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfeOFkt_Xscn"
      },
      "outputs": [],
      "source": []
    }
  ]
}