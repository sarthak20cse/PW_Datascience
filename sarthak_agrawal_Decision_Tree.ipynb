{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Code: DA-AG-012\n",
        "# Decision Tree | Assignment\n",
        "Instructions: Carefully read each question. Use Google Docs, Microsoft Word, or a similar tool\n",
        "to create a document where you type out each question along with its answer. Save the\n",
        "document as a PDF, and then upload it to the LMS. Please do not zip or archive the files before\n",
        "uploading them. Each question carries 20 marks.\n",
        "Total Marks: 100\n",
        "\n",
        "Question 1:  What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "\n",
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "\n",
        "\n",
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "\n",
        "Question 4: What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "\n",
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "\n",
        "Dataset Info:\n",
        "● Iris Dataset for classification tasks (sklearn.datasets.load_iris() or\n",
        "provided CSV).\n",
        "\n",
        "● Boston Housing Dataset for regression tasks\n",
        "(sklearn.datasets.load_boston() or provided CSV).\n",
        "\n",
        "Question 6:   Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "\n",
        "● Print the model’s accuracy and feature importances\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Question 7:  Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "Question 8: Write a Python program to:\n",
        "\n",
        "● Load the Boston Housing Dataset\n",
        "\n",
        "● Train a Decision Tree Regressor\n",
        "\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Question 9: Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "\n",
        "● Print the best parameters and the resulting model accuracy\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "\n",
        "● Handle the missing values\n",
        "\n",
        "● Encode the categorical features\n",
        "\n",
        "● Train a Decision Tree model\n",
        "\n",
        "● Tune its hyperparameters\n",
        "\n",
        "● Evaluate its performance\n",
        "\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting."
      ],
      "metadata": {
        "id": "YKtTQn72eZje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "### What is a Decision Tree, and how does it work in the context of classification?\n"
      ],
      "metadata": {
        "id": "EKMm5BtTuMJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "A Decision Tree is a supervised machine learning algorithm used for classification and regression.  \n",
        "In classification, it works by recursively splitting the dataset based on feature values.\n",
        "\n",
        "Each internal node represents a decision on a feature, each branch represents an outcome of the decision, and each leaf node represents a class label.\n",
        "\n",
        "The objective is to create pure subsets using impurity measures such as Gini Impurity or Entropy.\n"
      ],
      "metadata": {
        "id": "qSnobfVLuW01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "### Explain the concepts of Gini Impurity and Entropy as impurity measures.\n"
      ],
      "metadata": {
        "id": "UtvMarp7vshR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**Gini Impurity** measures how often a randomly chosen sample would be incorrectly classified.\n",
        "\n",
        "Gini = 1 − Σ(pᵢ²)\n",
        "\n",
        "Lower Gini indicates a better split.\n",
        "\n",
        "**Entropy** measures the randomness or uncertainty in the dataset.\n",
        "\n",
        "Entropy = −Σ(pᵢ log₂ pᵢ)\n",
        "\n",
        "Both impurity measures help determine the best feature to split the data by reducing impurity.\n"
      ],
      "metadata": {
        "id": "gkbJpBkrvsdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "### Difference between Pre-Pruning and Post-Pruning in Decision Trees\n"
      ],
      "metadata": {
        "id": "p9NrtW3lvsbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Pre-Pruning stops the tree growth early using constraints like max_depth and min_samples_split.\n",
        "\n",
        "Post-Pruning removes unnecessary branches after the tree is fully grown.\n",
        "\n",
        "**Advantages:**\n",
        "- Pre-Pruning reduces overfitting and training time.\n",
        "- Post-Pruning improves generalization on unseen data.\n"
      ],
      "metadata": {
        "id": "5eJryYRGvsZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "### What is Information Gain in Decision Trees?\n"
      ],
      "metadata": {
        "id": "VDzSz1P_vsXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Information Gain measures the reduction in entropy after splitting the dataset on a feature.\n",
        "\n",
        "Information Gain = Entropy(parent) − Σ Entropy(children)\n",
        "\n",
        "It is important because it helps select the feature that best separates the data.\n"
      ],
      "metadata": {
        "id": "WFUOsE3PvsU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "### Applications, Advantages, and Limitations of Decision Trees\n"
      ],
      "metadata": {
        "id": "CDRZ2c13vsSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**Applications:**\n",
        "- Medical diagnosis\n",
        "- Fraud detection\n",
        "- Credit scoring\n",
        "- Customer churn prediction\n",
        "\n",
        "**Advantages:**\n",
        "- Easy to interpret\n",
        "- Works with numerical and categorical data\n",
        "- Minimal data preprocessing\n",
        "\n",
        "**Limitations:**\n",
        "- Overfitting\n",
        "- Sensitive to small data changes\n",
        "- Less accurate than ensemble models\n"
      ],
      "metadata": {
        "id": "T_TUViHpvsQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "### Decision Tree Classifier using Gini Criterion\n"
      ],
      "metadata": {
        "id": "b411uipZvsNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCb4N-gov-LX",
        "outputId": "f41f9294-c1f8-4f5d-f5c4-b759778674a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Feature Importances: [0.         0.01667014 0.90614339 0.07718647]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "### Compare max_depth = 3 with a fully-grown Decision Tree\n"
      ],
      "metadata": {
        "id": "JfOw_aLmvsLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "full_tree = DecisionTreeClassifier(random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "full_accuracy = accuracy_score(y_test, full_tree.predict(X_test))\n",
        "\n",
        "limited_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "limited_tree.fit(X_train, y_train)\n",
        "limited_accuracy = accuracy_score(y_test, limited_tree.predict(X_test))\n",
        "\n",
        "print(\"Full Tree Accuracy:\", full_accuracy)\n",
        "print(\"Max Depth = 3 Accuracy:\", limited_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TjvoZq5wBTT",
        "outputId": "47987378-3ed0-4a8e-e265-d5d69effa824"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Tree Accuracy: 1.0\n",
            "Max Depth = 3 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "### Decision Tree Regressor on Boston Housing Dataset\n"
      ],
      "metadata": {
        "id": "9ZD97ktavsI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Load Boston Housing dataset from OpenML\n",
        "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
        "\n",
        "X = boston.data\n",
        "y = boston.target.astype(float)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Output\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"Feature Importances:\", regressor.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kQTZr-xwD9J",
        "outputId": "d02d22e5-673c-4b47-c98b-a98d53605dfe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 10.416078431372549\n",
            "Feature Importances: [5.12956739e-02 3.35270585e-03 5.81619171e-03 2.27940651e-06\n",
            " 2.71483790e-02 6.00326256e-01 1.36170630e-02 7.06881622e-02\n",
            " 1.94062297e-03 1.24638653e-02 1.10116089e-02 9.00872742e-03\n",
            " 1.93328464e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9\n",
        "### Hyperparameter Tuning using GridSearchCV\n"
      ],
      "metadata": {
        "id": "dlE4u-xqvsGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"max_depth\": [2, 3, 4, 5],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "grid = GridSearchCV(dt, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9vCKz5KwKXG",
        "outputId": "6a196167-7d83-4075-dfa7-5174b45e3d47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Best Accuracy: 0.9416666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10\n",
        "### Healthcare Decision Tree – Step-by-Step Process\n"
      ],
      "metadata": {
        "id": "mV9smDJYvsEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "1. Handle Missing Values:\n",
        "   - Numerical features using mean or median.\n",
        "   - Categorical features using mode or a new category.\n",
        "\n",
        "2. Encode Categorical Features:\n",
        "   - One-Hot Encoding\n",
        "   - Label Encoding\n",
        "\n",
        "3. Train Decision Tree:\n",
        "   - Choose Gini or Entropy\n",
        "   - Split data into training and testing sets\n",
        "\n",
        "4. Hyperparameter Tuning:\n",
        "   - max_depth\n",
        "   - min_samples_split\n",
        "   - GridSearchCV\n",
        "\n",
        "5. Model Evaluation:\n",
        "   - Accuracy\n",
        "   - Precision and Recall\n",
        "   - Confusion Matrix\n",
        "   - ROC-AUC\n",
        "\n",
        "**Business Value:**\n",
        "The model helps in early disease detection, reduces healthcare costs, improves patient outcomes, and supports data-driven clinical decisions.\n"
      ],
      "metadata": {
        "id": "yQnVmE22vsCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "II_PyRzEuRgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeQ5Xf45ePr2"
      },
      "outputs": [],
      "source": []
    }
  ]
}